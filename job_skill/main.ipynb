{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e153f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "from job_desc import *\n",
    "from openai_api import *\n",
    "from job_viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea818fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api(df1):\n",
    "    # loading api key\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "    df1['Skills_and_Percentage'] = None\n",
    "    df1['Programming Languages'] = None\n",
    "    df1['Tools'] = None\n",
    "    df1['Technical Skills'] = None\n",
    "\n",
    "    for index, desc in df1.iterrows():\n",
    "        result = call_api_skills_percent(api_key, desc['Job Description'])\n",
    "        result2 = call_api_tech_skills(api_key, desc['Job Description'])\n",
    "        \n",
    "        # Storing the values from the dictionary\n",
    "        skills = result['Skills']\n",
    "        percentage = result['Percentage']\n",
    "\n",
    "        # Zipping the values together\n",
    "        skills_and_percentage = zip(skills, percentage)\n",
    "\n",
    "        # Converting the zip object to a list\n",
    "        skills_and_percentage = list(skills_and_percentage)\n",
    "\n",
    "        #storing Skills_and_Percentage in df\n",
    "        df1.at[index, 'Skills_and_Percentage'] = skills_and_percentage\n",
    "\n",
    "        # Storing the values from the dictionary\n",
    "        p_lang = result2['Programming Languages']\n",
    "        tools = result2['Tools']\n",
    "        tech_skills = result2['Technical Skills']\n",
    "\n",
    "        # storing in df\n",
    "        df1.at[index, 'Programming Languages'] = p_lang\n",
    "        df1.at[index, 'Tools'] = tools\n",
    "        df1.at[index, 'Technical Skills'] = tech_skills\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get user input on job description in an array\n",
    "try:\n",
    "    inputarr=list()\n",
    "    usr_in_op,usr_in = '',''\n",
    "\n",
    "    while usr_in_op != 'X':\n",
    "        usr_in_op = input(\"Would you like to enter job description or job URL A: description B. URL X. Exit\")\n",
    "        input_jobs = int(input(\"How many jobs would you like to enter(integers)? MIN:1 & MAX:10 \\n\"))\n",
    "\n",
    "        if input_jobs < 1 or input_jobs > 10:\n",
    "            print(\"Number of jobs anticipated is not valid. Please enter an integer between 1 and 10 (both inclusive)\")\n",
    "            usr_in_op = 'X' \n",
    "\n",
    "        if usr_in_op == 'A':\n",
    "\n",
    "            for i in range(input_jobs):\n",
    "                print(\"######Job Description number######\",i+1)\n",
    "                inputstr = input(\"\\nEnter job description:\")\n",
    "                #print(inputstr)\n",
    "                while inputstr == '':\n",
    "                    print(\"You are in a time loop. Input job description to get out of it\")\n",
    "                    inputstr = input(\"\\nEnter job description:\")\n",
    "                inputarr.append(inputstr)\n",
    "            usr_in=usr_in_op\n",
    "            usr_in_op = 'X'\n",
    "\n",
    "        elif usr_in_op == 'B':\n",
    "\n",
    "            for i in range(input_jobs):\n",
    "                print(\"######Job URL number######\",i+1)\n",
    "                inputstr = input(\"\\nEnter job URL:\")\n",
    "                #print(inputstr)\n",
    "                while inputstr == '':\n",
    "                    print(\"You are in a time loop. Input job description to get out of it\")\n",
    "                    inputstr = input(\"\\nEnter job description:\")\n",
    "                inputarr.append(inputstr)\n",
    "                #execute function\n",
    "            usr_in=usr_in_op\n",
    "            usr_in_op = 'X'\n",
    "\n",
    "    if usr_in == 'A':\n",
    "        df1 = pd.DataFrame(list(zip(\"\", \"\",\"\",\"\",\"\")), columns = [\"Job URL\",\"Job Description\",\"Job Title\",\"Job Location\"])\n",
    "        df1[\"Job Description\"]=inputarr\n",
    "        df1 = call_api(df1)\n",
    "    elif usr_in == 'B':\n",
    "        df1 = scrape_job_description(inputarr)\n",
    "        ignore_df = None\n",
    "        ignore_df = df1[df1[\"Job Description\"] == \"Invalid URL, analysis skipped\"]\n",
    "        # This is the dataframe with all valid inputs for downstream assessment\n",
    "        df1 = df1[df1[\"Job Description\"] != \"Invalid URL, analysis skipped\"]\n",
    "        df1 =call_api(df1)\n",
    "\n",
    "except ValueError:\n",
    "      print(\"Error: Number of jobs anticipated is not valid. Please enter an integer between 1 and 10 (both inclusive)\")\n",
    "except Exception:\n",
    "      print(\"An unknown error occurred. Please try again with valid inputs.\")\n",
    "\n",
    "\n",
    "\n",
    "#Output the invalid job urls and notify user\n",
    "if len(ignore_df) > 0:\n",
    "    print (\"Invalid jobs will be skipped. Number of jobs skipped in current run are:\",len(ignore_df))\n",
    "    print (\"\\nFollowing are the details of the jobs skipped:\",(ignore_df))          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac05a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected jobs only\n",
    "pd.options.display.max_colwidth = 50\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46967b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will return the main df to do rest of processing \n",
    "call_api(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c28179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Job URL  \\\n",
      "0         0.0      NaN   \n",
      "1         1.0      NaN   \n",
      "2         NaN      NaN   \n",
      "3         NaN      NaN   \n",
      "4         NaN      NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Job Description  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         There’s a lot of buzz around the next leaps in wireless network optimization, leveraging data science, big data and machine learning. Join a team that is re-thinking how we optimize our wireless network by blending wireless engineering, computational analysis, and programming. At TELUS, with over 9 million subscribers, there’s a lot of data being generated from our network, and with this lies untapped potential for data mining and advanced insights towards improving our customers’ wireless experience.  As a Data Scientist and member of Eastern Canada's wireless network performance team, you'll play a critical role in the optimization of the Radio Access Network (RAN) by developing automation policies and algorithms, workflow and data processing services and finding new angles/methods to improve network performance, efficiently. You'll join the larger Wireless Networks & Services DevOps team that is providing TELUS customers with the most reliable network and the best user experience in every region of the country.  In our team, you'll ensure our customers' wireless experience continuously improves. Your \"think outside of the box\" and innovation will help shape our Key Performance Indicators (KPIs) that we use to govern our customers' wireless experience. Your data science and automation mindset will provide inputs to our team to improve the quality and efficiency of the way we do network performance engineering.  What You’ll Do Use data to: discover opportunities to improve our processes enhance our decision-making ability Explore data to: design innovative predictive models and metrics develop dashboards to uncover actionable insights Lead the development, validation, and deployment of AI/ML models and bring these to production You’ll be exposed to the latest wireless technology innovation planned for TELUS, and be ready to support their launch from a performance management perspective  What You Bring  A passion for how data can be used to uncover new insights, solve problems and drive effective actions A strategic thinking and a bias for action and driving change Curious and creative in looking at metrics to identify new critical metrics for the team Master visualizations and be able to explain complex topics to non-technical audiences You value deploying Machine Learning and AI solutions for problems solving You are a strong software developer, you regularly and primarily develop in Python You are familiar with at least one of the cloud computing platforms - GCP, AWS, Azure Minimum of 3+ years of working with large data sets and analyzing data to identify patterns and in writing and testing code proficiently  Great-to-haves  Google Cloud Platform and tools knowledge Bachelor degree in Computer Science or Engineering or equivalent, or equivalent education and/or experience   \n",
      "1  About the job TD Description  Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think \"TD\" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.  Stay current and competitive. Carve out a career for yourself. Grow with us. Here's our story: jobs.td.com  Department Overview  What does TD stand for? For starters, we believe in visionary leadership and insights. We believe in using every resource at our disposal to better serve our clients, and for almost every department, that begins with data.  As part of our Data and Analytics team, you'll be a fundamental part of crafting business processes enterprise-wide by analyzing vast amounts of past and present data.  TD's vision for the future? Tailored, customized banking products, services and experiences for every single customer. If you've been in business as long as we have, you know there's no such thing as one size fits all, and a diverse, inclusive Data Analytics team is a massive part of that future achievement.  Job Description  About this Role  For this role, we're counting on your intensive technical leadership to forge our path moving forward. As an emissary of the crucial nature of data science, you'll work in close proximity others across the bank to identify and pursue new opportunities wherever they lie. You'll play a crucial role on cross functional teams of data scientists, data and IT engineers and business process owners to build out and implement world-class analytic solutions enterprise wide. You can handle just how much data TD has, and cannot wait to help build statistical models that scale to them.  We are looking for someone to help parse our vast data and identify needs and analytical trends employing industry leading techniques and theories to improve TD's business practices enterprise wide.  As a Data Scientist III, these are the essential qualifications of this role:  Provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become core deliverables Work closely with business owners to find opportunities and serve as an ambassador for data science Design and deliver enterprise analytic solutions for customers Develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques Build complex statistical models that learn from and scale to petabytes of data. Analytical thought leadership and stay current on developments in data mining and the application of data science Work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size Generally accountable for a significant business management area that typically has enterprise wide impact or accountability Enterprise or functional expert, requiring broad managerial and deep specialized knowledge at the enterprise, business, regulatory and industry levels  Job Requirements  What can you bring to TD? Tell us about your most relevant experience, credentials and knowledge for this role, as well as these essential requirements and attributes:  Undergraduate degree or technical certificate Ten (10) or more years of relevant experience Familiarity and experience with Optimization and Operations Research methodologies as applied in a commercial Marketing context Familiarity and experience with MarTech tools and process and the activation of machine learning and analytical outputs within these tools  Additional Information  #datascientist  Inclusiveness  At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               NaN   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               NaN   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               NaN   \n",
      "\n",
      "   Job Title              Job Location  \\\n",
      "0        NaN  Toronto, Ontario, Canada   \n",
      "1        NaN  Toronto, Ontario, Canada   \n",
      "2        NaN       Kelowna, BC, Canada   \n",
      "3        NaN            Vernon, Canada   \n",
      "4        NaN            Vernon, Canada   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                Skills_and_Percentage  \\\n",
      "0                                                                                                                             [('Data Science', '25'), ('Big Data', '15'), ('Machine Learning', '20'), ('Software Development', '20'), ('Cloud Computing Platforms', '10'), ('Strategic Thinking', '5'), ('Data Visualization', '5')]   \n",
      "1  [('                 Technical Leadership', '10'), ('                 Data Science', '20'), ('                 Business Processes', '10'), ('                 Visionary Leadership', '10'), ('                 Data Analysis', '20'), ('                 Machine Learning', '20'), ('                 Statistical Modeling', '10')]   \n",
      "2                                                                                                                                                                                                                                                                                                                                 NaN   \n",
      "3                                                                                                                                                                                                                                                                                                                                 NaN   \n",
      "4                                                                                                                                                                                                                                                                                                                                 NaN   \n",
      "\n",
      "  Programming Languages  \\\n",
      "0            ['Python']   \n",
      "1   ['Python, R, Java']   \n",
      "2            ['Python']   \n",
      "3            ['Python']   \n",
      "4                   NaN   \n",
      "\n",
      "                                                                   Tools  \\\n",
      "0                                  ['Google Cloud Platform, AWS, Azure']   \n",
      "1  ['Optimization and Operations Research methodologies, MarTech tools']   \n",
      "2                                               ['Tableu, Excel, Azure']   \n",
      "3                                  ['Google Cloud Platform, AWS, Azure']   \n",
      "4                                                                    NaN   \n",
      "\n",
      "                                                                                                                                                                                                    Technical Skills  \n",
      "0  ['Data Science, Big Data, Machine Learning, Wireless Engineering, Computational Analysis, Data Mining, Automation Policies and Algorithms, Workflow and Data Processing Services, AI/ML Models, Visualizations.']  \n",
      "1                                                                                              ['Data Mining, Machine Learning, Statistical Modeling, Business Insights, Data Analysis, Data Management Solutions.']  \n",
      "2                                                                                              ['Data Mining, Machine Learning, Statistical Modeling, Business Insights, Data Analysis, Data Management Solutions.']  \n",
      "3                                                                                              ['Data Mining, Machine Learning, Statistical Modeling, Business Insights, Data Analysis, Data Management Solutions.']  \n",
      "4                                                                                                                                                                                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "#made a test file with copy of 'call_api(df1)' returned df so can restart kernel and still have access to df\n",
    "df_test=pd.read_csv('test_file.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0e26d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Programming Languages encoding field is specified without a type; the type cannot be automatically inferred because the data is not specified as a pandas.DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/vegalite/v4/api.py:384\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTopLevelMixin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m jsonschema\u001b[38;5;241m.\u001b[39mValidationError:\n\u001b[1;32m    386\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:346\u001b[0m, in \u001b[0;36mSchemaBase.to_dict\u001b[0;34m(self, validate, ignore, context)\u001b[0m\n\u001b[1;32m    344\u001b[0m     result \u001b[38;5;241m=\u001b[39m _todict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;241m0\u001b[39m], validate\u001b[38;5;241m=\u001b[39msub_validate, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args:\n\u001b[0;32m--> 346\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_validate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instance has both a value and properties : \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot serialize to dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m    355\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:80\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     81\u001b[0m         k: _todict(v, validate, context)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:81\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 81\u001b[0m         k: \u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:78\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict(validate\u001b[38;5;241m=\u001b[39mvalidate, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     81\u001b[0m         k: _todict(v, validate, context)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict(validate\u001b[38;5;241m=\u001b[39mvalidate, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     81\u001b[0m         k: _todict(v, validate, context)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:76\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert an object to a dict representation.\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, SchemaBase):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/vegalite/v4/api.py:2020\u001b[0m, in \u001b[0;36mChart.to_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2018\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mInlineData(values\u001b[38;5;241m=\u001b[39m[{}])\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Chart, copy)\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/vegalite/v4/api.py:384\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTopLevelMixin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m jsonschema\u001b[38;5;241m.\u001b[39mValidationError:\n\u001b[1;32m    386\u001b[0m     dct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:346\u001b[0m, in \u001b[0;36mSchemaBase.to_dict\u001b[0;34m(self, validate, ignore, context)\u001b[0m\n\u001b[1;32m    344\u001b[0m     result \u001b[38;5;241m=\u001b[39m _todict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;241m0\u001b[39m], validate\u001b[38;5;241m=\u001b[39msub_validate, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args:\n\u001b[0;32m--> 346\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_validate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instance has both a value and properties : \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot serialize to dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m    355\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:80\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     81\u001b[0m         k: _todict(v, validate, context)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:81\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 81\u001b[0m         k: \u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:76\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert an object to a dict representation.\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, SchemaBase):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:346\u001b[0m, in \u001b[0;36mSchemaBase.to_dict\u001b[0;34m(self, validate, ignore, context)\u001b[0m\n\u001b[1;32m    344\u001b[0m     result \u001b[38;5;241m=\u001b[39m _todict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;241m0\u001b[39m], validate\u001b[38;5;241m=\u001b[39msub_validate, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args:\n\u001b[0;32m--> 346\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_validate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instance has both a value and properties : \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot serialize to dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m    355\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:80\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     81\u001b[0m         k: _todict(v, validate, context)\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:81\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 81\u001b[0m         k: \u001b[43m_todict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Undefined\n\u001b[1;32m     84\u001b[0m     }\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/utils/schemapi.py:76\u001b[0m, in \u001b[0;36m_todict\u001b[0;34m(obj, validate, context)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert an object to a dict representation.\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, SchemaBase):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_todict(v, validate, context) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/altair/vegalite/v4/schema/channels.py:44\u001b[0m, in \u001b[0;36mFieldChannelMixin.to_dict\u001b[0;34m(self, validate, ignore, context)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m encoding field is specified without a type; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe type cannot be inferred because it does not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch any column in the data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shorthand))\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m encoding field is specified without a type; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe type cannot be automatically inferred because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe data is not specified as a pandas.DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shorthand))\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Shorthand is not a string; we pass the definition to field,\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# and do not do any parsing.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield\u001b[39m\u001b[38;5;124m'\u001b[39m: shorthand}\n",
      "\u001b[0;31mValueError\u001b[0m: Programming Languages encoding field is specified without a type; the type cannot be automatically inferred because the data is not specified as a pandas.DataFrame."
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse the df to make seperate df for each column, currently using df_test but will use original call\n",
    "lang = parse_df(df_test, 'Programming Languages')\n",
    "tools = parse_df(df_test, 'Tools')\n",
    "\n",
    "#call this function to return the visual\n",
    "visualize_info(lang, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045cbb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-08ab665fbb6f441eb661f1a9a2d3221c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-08ab665fbb6f441eb661f1a9a2d3221c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-08ab665fbb6f441eb661f1a9a2d3221c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"arc\", \"outerRadius\": 120}, \"encoding\": {\"color\": {\"field\": \"Job Location\", \"legend\": null, \"type\": \"nominal\"}, \"theta\": {\"field\": \"count\", \"stack\": true, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"radius\": 140, \"size\": 10}, \"encoding\": {\"color\": {\"field\": \"Job Location\", \"legend\": null, \"type\": \"nominal\"}, \"text\": {\"field\": \"Job Location\", \"type\": \"nominal\"}, \"theta\": {\"field\": \"count\", \"stack\": true, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-edf02cb3a74c3b2c849e90280ee0dd16\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-edf02cb3a74c3b2c849e90280ee0dd16\": [{\"Job Location\": \"Kelowna\", \"count\": 1}, {\"Job Location\": \"Toronto\", \"count\": 2}, {\"Job Location\": \"Vedwdwdrnon\", \"count\": 1}, {\"Job Location\": \"Vernon\", \"count\": 4}, {\"Job Location\": \"dwd\", \"count\": 1}, {\"Job Location\": \"rff\", \"count\": 1}, {\"Job Location\": \"wd\", \"count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call this function to return a pie chart to show distirbution of job locations \n",
    "#(no need to call parse_df function like above)\n",
    "\n",
    "visualize_location(df_test, 'Job Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81659dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fine tune output.. currently giving error on dict sizes plus need to add serial \n",
    "#and correct numbers in front of answer\n",
    "skills = df_test['Technical Skills'].tolist()\n",
    "\n",
    "df = call_api_interview('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', skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809fde55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignored jobs due to error\n",
    "ignore_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e62f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "df1['Job Location'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7459fc3de7a9cfbb16956cc8e27f933e0ea1512a8cf97ca2195aa9f74a47b2b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
